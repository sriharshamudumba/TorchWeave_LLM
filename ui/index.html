<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
    <title>TorchWeave LLM - Performance Comparison</title>
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            padding: 20px;
            color: #333;
        }
        .container { max-width: 1400px; margin: 0 auto; display: grid; gap: 25px; }
        .header {
            background: rgba(255,255,255,0.95);
            backdrop-filter: blur(10px);
            padding: 30px; border-radius: 16px; text-align: center;
            box-shadow: 0 8px 32px rgba(0,0,0,0.1);
        }
        .header h1 {
            font-size: 2.5em;
            background: linear-gradient(135deg, #667eea, #764ba2);
            -webkit-background-clip: text; -webkit-text-fill-color: transparent; margin-bottom: 10px;
        }
        .header p { color: #666; font-size: 1.1em; }

        .section {
            background: rgba(255,255,255,0.95); backdrop-filter: blur(10px);
            padding: 30px; border-radius: 16px; box-shadow: 0 8px 32px rgba(0,0,0,0.1);
        }
        .section h2 {
            color: #667eea; margin-bottom: 20px; font-size: 1.8em;
            border-bottom: 3px solid rgba(102, 126, 234, 0.2); padding-bottom: 10px;
        }

        .form-grid { display: grid; grid-template-columns: repeat(auto-fit, minmax(350px, 1fr)); gap: 30px; }
        .comparison-grid { display: grid; grid-template-columns: 1fr 1fr; gap: 30px; }
        .form-section { 
            background: rgba(102, 126, 234, 0.05); 
            padding: 25px; border-radius: 12px; 
            border: 2px solid rgba(102, 126, 234, 0.2); 
        }
        .form-section h3 { color: #667eea; margin-bottom: 20px; font-size: 1.3em; }

        .input-group { margin-bottom: 20px; }
        .input-group label { display: block; margin-bottom: 8px; font-weight: bold; color: #555; }
        .input-group input, .input-group select, .input-group textarea {
            width: 100%; padding: 12px; border: 2px solid rgba(102, 126, 234, 0.2);
            border-radius: 8px; font-size: 1em; transition: border-color 0.3s ease;
        }
        .input-group input:focus, .input-group select:focus, .input-group textarea:focus {
            outline: none; border-color: #667eea; box-shadow: 0 0 0 3px rgba(102, 126, 234, 0.1);
        }

        .btn {
            background: linear-gradient(135deg, #667eea, #764ba2); color: white; border: none;
            padding: 12px 24px; border-radius: 8px; cursor: pointer; font-size: 1em; font-weight: 600;
            margin: 8px 8px 8px 0; transition: all 0.3s ease; box-shadow: 0 4px 15px rgba(102, 126, 234, 0.3);
            width: 100%;
        }
        .btn:hover { transform: translateY(-2px); box-shadow: 0 6px 20px rgba(102, 126, 234, 0.4); }
        .btn:disabled { opacity: 0.5; cursor: not-allowed; transform: none; }
        .btn-outline { background: transparent; border: 2px solid #667eea; color: #667eea; }
        .btn-outline:hover { background: #667eea; color: white; }

        .info-box  { background: rgba(40, 167, 69, 0.1); border: 2px solid rgba(40, 167, 69, 0.3); border-radius: 8px; padding: 15px; margin: 15px 0; }
        .warning-box { background: rgba(255, 193, 7, 0.1); border: 2px solid rgba(255, 193, 7, 0.3); border-radius: 8px; padding: 15px; margin: 15px 0; }

        .status-grid { display: grid; grid-template-columns: repeat(auto-fit, minmax(150px, 1fr)); gap: 15px; margin-bottom: 20px; }
        .status-card { background: rgba(102, 126, 234, 0.1); padding: 15px; border-radius: 8px; text-align: center; }
        .status-card h4 { color: #667eea; margin-bottom: 5px; }

        .result-box { 
            background: rgba(40, 167, 69, 0.1); 
            border: 2px solid rgba(40, 167, 69, 0.3); 
            border-radius: 8px; padding: 15px; margin-top: 15px; 
            display: none; 
        }
        .error-box  { 
            background: rgba(220, 53, 69, 0.1); 
            border: 2px solid rgba(220, 53, 69, 0.3); 
            border-radius: 8px; padding: 15px; margin-top: 15px; 
            display: none; 
        }

        .progress-box {
            background: rgba(255, 193, 7, 0.1);
            border: 2px solid rgba(255, 193, 7, 0.3);
            border-radius: 8px;
            padding: 15px;
            margin-top: 15px;
            display: none;
        }

        .progress-bar {
            width: 100%;
            height: 20px;
            background: rgba(255, 255, 255, 0.3);
            border-radius: 10px;
            overflow: hidden;
            margin: 10px 0;
        }

        .progress-fill {
            height: 100%;
            background: linear-gradient(90deg, #667eea, #764ba2);
            width: 0%;
            transition: width 0.3s ease;
            border-radius: 10px;
        }

        .metrics-comparison {
            background: rgba(255, 255, 255, 0.98);
            border-radius: 12px;
            padding: 25px;
            margin-top: 20px;
            border: 2px solid rgba(102, 126, 234, 0.3);
            display: none;
        }

        .metrics-table {
            width: 100%;
            border-collapse: collapse;
            margin-top: 15px;
        }

        .metrics-table th, .metrics-table td {
            padding: 12px;
            text-align: left;
            border-bottom: 1px solid rgba(102, 126, 234, 0.2);
        }

        .metrics-table th {
            background: rgba(102, 126, 234, 0.1);
            font-weight: bold;
            color: #667eea;
        }

        .performance-winner {
            background: rgba(40, 167, 69, 0.1) !important;
            font-weight: bold;
        }

        .performance-summary {
            background: rgba(102, 126, 234, 0.1);
            padding: 15px;
            border-radius: 8px;
            margin-top: 15px;
            text-align: center;
        }

        .spinner { 
            display: inline-block; width: 20px; height: 20px; 
            border: 3px solid rgba(255,255,255,0.3); border-radius: 50%; 
            border-top-color: #fff; animation: spin 1s ease-in-out infinite; 
        }
        @keyframes spin { to { transform: rotate(360deg); } }

        .connection-status {
            background: rgba(220, 53, 69, 0.1);
            border: 2px solid rgba(220, 53, 69, 0.3);
            border-radius: 8px;
            padding: 15px;
            margin-bottom: 20px;
            display: none;
        }
        .connection-status.connected {
            background: rgba(40, 167, 69, 0.1);
            border-color: rgba(40, 167, 69, 0.3);
        }

        .timeout-settings {
            background: rgba(102, 126, 234, 0.05);
            border: 2px solid rgba(102, 126, 234, 0.2);
            border-radius: 8px;
            padding: 15px;
            margin: 15px 0;
        }

        .model-size-warning {
            background: rgba(255, 193, 7, 0.1);
            border: 2px solid rgba(255, 193, 7, 0.3);
            border-radius: 8px;
            padding: 10px;
            margin: 10px 0;
            font-size: 0.9em;
        }
    </style>
</head>
<body>
<div class="container">
    <div class="header">
        <h1>TorchWeave LLM</h1>
        <p>High-Performance Language Model Inference with Continuous Batching vs Baseline Comparison</p>
    </div>

    <div id="connection-status" class="connection-status">
        <strong>Connection Status:</strong> <span id="connection-message">Checking connections...</span>
    </div>

    <div class="section">
        <h2>System Status</h2>
        <div class="status-grid">
            <div class="status-card"><h4>TorchWeave Server</h4><p id="server-status">Checking...</p></div>
            <div class="status-card"><h4>Model Manager</h4><p id="model-manager-status">Checking...</p></div>
            <div class="status-card"><h4>Frontend</h4><p>Port 3000</p></div>
        </div>
        <button onclick="checkSystemHealth()" class="btn btn-outline">Check System Health</button>
        
        <div class="timeout-settings">
            <h4>Timeout Settings</h4>
            <div class="input-group">
                <label for="model-load-timeout">Model Load Timeout (seconds):</label>
                <input id="model-load-timeout" type="number" value="120" min="30" max="600" />
                <small>Large models (1B+ parameters) may take 60-120 seconds to load</small>
            </div>
            <div class="input-group">
                <label for="generation-timeout">Generation Timeout (seconds):</label>
                <input id="generation-timeout" type="number" value="60" min="10" max="300" />
            </div>
        </div>
        
        <div id="health-status" class="info-box" style="display:none;"></div>
    </div>

    <div class="section">
        <h2>Model Management</h2>
        <div class="form-grid">
            <div class="form-section">
                <h3>Load Model</h3>
                <form id="load-model-form">
                    <div class="input-group">
                        <label for="model-id">Model ID:</label>
                        <select id="model-id" name="model_id" required onchange="updateModelWarning()">
                            <option value="">Select a model...</option>
                            <option value="distilgpt2">DistilGPT-2 (82M) - Fastest</option>
                            <option value="gpt2">GPT-2 (124M) - Fast</option>
                            <option value="microsoft/DialoGPT-small">DialoGPT Small (117M) - Fast</option>
                            <option value="TinyLlama/TinyLlama-1.1B-Chat-v1.0">TinyLlama Chat (1.1B) - Slower load</option>
                        </select>
                    </div>
                    <div class="input-group">
                        <label for="custom-model">Or Custom Model ID:</label>
                        <input id="custom-model" name="custom_model_id" type="text" placeholder="e.g., microsoft/DialoGPT-medium" onchange="updateModelWarning()"/>
                    </div>
                    <div id="model-size-warning" class="model-size-warning" style="display:none;"></div>
                    <div class="input-group">
                        <label>
                            <input type="checkbox" id="load-both-services" checked /> 
                            Load in both services (recommended)
                        </label>
                        <small>Unchecking will load only in Model Manager for faster loading</small>
                    </div>
                    <button type="submit" class="btn">Load Model</button>
                </form>
                <div id="load-progress" class="progress-box">
                    <div id="load-progress-text">Loading model...</div>
                    <div class="progress-bar">
                        <div id="load-progress-fill" class="progress-fill"></div>
                    </div>
                    <small id="load-progress-detail">Initializing...</small>
                </div>
                <div id="load-result" class="result-box"></div>
                <div id="load-error" class="error-box"></div>
            </div>

            <div class="form-section">
                <h3>Model Operations</h3>
                <div class="input-group"><button onclick="viewModels()" class="btn btn-outline">View Loaded Models</button></div>
                <div class="input-group"><button onclick="viewAvailable()" class="btn btn-outline">View Available Models</button></div>
                <div class="input-group"><button onclick="viewStats()" class="btn btn-outline">System Stats</button></div>
                <div id="model-info" class="info-box" style="display:none;">
                    <div id="model-info-content"></div>
                </div>
            </div>
        </div>
    </div>

    <div class="section">
        <h2>Performance Comparison: TorchWeave vs Baseline</h2>
        <div class="comparison-grid">
            <div class="form-section">
                <h3>🚀 TorchWeave (Continuous Batching)</h3>
                <form id="torchweave-form">
                    <div class="input-group">
                        <label for="tw-prompt">Prompt:</label>
                        <textarea id="tw-prompt" name="prompt" rows="4" required>Write a short story about an AI that discovers creativity...</textarea>
                    </div>
                    <div class="input-group">
                        <label for="tw-tokens">Max New Tokens:</label>
                        <input id="tw-tokens" name="max_new_tokens" type="number" value="128" min="1" max="512"/>
                    </div>
                    <div class="input-group">
                        <label for="tw-temp">Temperature:</label>
                        <input id="tw-temp" name="temperature" type="number" value="0.7" step="0.1" min="0.1" max="2.0"/>
                    </div>
                    <button type="submit" class="btn">Generate with TorchWeave</button>
                </form>
                <div id="tw-result" class="result-box"></div>
                <div id="tw-error" class="error-box"></div>
            </div>

            <div class="form-section">
                <h3>📊 Baseline (Standard Inference)</h3>
                <form id="baseline-form">
                    <div class="input-group">
                        <label for="bl-model">Model ID:</label>
                        <input id="bl-model" name="model_id" type="text" value="distilgpt2" required/>
                    </div>
                    <div class="input-group">
                        <label for="bl-prompt">Prompt:</label>
                        <textarea id="bl-prompt" name="prompt" rows="4" required>Write a short story about an AI that discovers creativity...</textarea>
                    </div>
                    <div class="input-group">
                        <label for="bl-length">Max Length:</label>
                        <input id="bl-length" name="max_length" type="number" value="128" min="1" max="512"/>
                    </div>
                    <div class="input-group">
                        <label for="bl-temp">Temperature:</label>
                        <input id="bl-temp" name="temperature" type="number" value="0.7" step="0.1" min="0.1" max="2.0"/>
                    </div>
                    <button type="submit" class="btn">Generate with Baseline</button>
                </form>
                <div id="bl-result" class="result-box"></div>
                <div id="bl-error" class="error-box"></div>
            </div>
        </div>

        <button onclick="runComparison()" class="btn" style="margin-top: 20px;">🔥 Run Side-by-Side Comparison</button>
        
        <div id="metrics-comparison" class="metrics-comparison">
            <h3>📈 Performance Metrics Comparison</h3>
            <table class="metrics-table">
                <thead>
                    <tr>
                        <th>Metric</th>
                        <th>TorchWeave</th>
                        <th>Baseline</th>
                        <th>Winner</th>
                    </tr>
                </thead>
                <tbody id="metrics-table-body">
                </tbody>
            </table>
            <div id="performance-summary" class="performance-summary"></div>
        </div>

        <div class="warning-box">
            <strong>Note:</strong> Load a model first using the Model Management section above. Both methods will use the same loaded model for fair comparison.
        </div>
    </div>
</div>

<script>
    let lastTorchweaveResult = null;
    let lastBaselineResult = null;
    let systemHealthy = false;

    // Enhanced configuration with dynamic timeouts
    const API_CONFIG = {
        TORCHWEAVE_BASE: '', 
        MODEL_MANAGER_BASE: '', 
        DEFAULT_TIMEOUT: 30000,
        get MODEL_LOAD_TIMEOUT() {
            const timeoutInput = document.getElementById('model-load-timeout');
            return (parseInt(timeoutInput?.value) || 120) * 1000;
        },
        get GENERATION_TIMEOUT() {
            const timeoutInput = document.getElementById('generation-timeout');
            return (parseInt(timeoutInput?.value) || 60) * 1000;
        }
    };

    // Model size information for better user guidance
    const MODEL_INFO = {
        'distilgpt2': { size: '82M', loadTime: '5-15s', category: 'small' },
        'gpt2': { size: '124M', loadTime: '10-20s', category: 'small' },
        'microsoft/DialoGPT-small': { size: '117M', loadTime: '10-20s', category: 'small' },
        'TinyLlama/TinyLlama-1.1B-Chat-v1.0': { size: '1.1B', loadTime: '30-90s', category: 'large' }
    };

    // Update model warning based on selection
    function updateModelWarning() {
        const modelSelect = document.getElementById('model-id');
        const customInput = document.getElementById('custom-model');
        const warningDiv = document.getElementById('model-size-warning');
        
        const selectedModel = customInput.value.trim() || modelSelect.value;
        const info = MODEL_INFO[selectedModel];
        
        if (info) {
            warningDiv.style.display = 'block';
            if (info.category === 'large') {
                warningDiv.innerHTML = `
                    <strong>⚠️ Large Model Selected (${info.size})</strong><br>
                    Expected load time: ${info.loadTime}<br>
                    Consider using a smaller model for faster loading.
                `;
            } else {
                warningDiv.innerHTML = `
                    <strong>✅ Efficient Model (${info.size})</strong><br>
                    Expected load time: ${info.loadTime}
                `;
            }
        } else if (selectedModel) {
            warningDiv.style.display = 'block';
            warningDiv.innerHTML = `
                <strong>🔍 Custom Model</strong><br>
                Load time depends on model size. Large models (>1B parameters) may take 60+ seconds.
            `;
        } else {
            warningDiv.style.display = 'none';
        }
    }

    // Enhanced progress tracking for model loading
    function showLoadingProgress(modelId) {
        const progressBox = document.getElementById('load-progress');
        const progressText = document.getElementById('load-progress-text');
        const progressFill = document.getElementById('load-progress-fill');
        const progressDetail = document.getElementById('load-progress-detail');
        
        progressBox.style.display = 'block';
        progressText.textContent = `Loading ${modelId}...`;
        progressDetail.textContent = 'Downloading and initializing model...';
        
        let progress = 0;
        const interval = setInterval(() => {
            progress += Math.random() * 15;
            if (progress > 90) progress = 90;
            progressFill.style.width = `${progress}%`;
            
            if (progress < 30) {
                progressDetail.textContent = 'Downloading model files...';
            } else if (progress < 60) {
                progressDetail.textContent = 'Loading model into memory...';
            } else if (progress < 90) {
                progressDetail.textContent = 'Initializing model...';
            }
        }, 1000);
        
        return {
            complete: () => {
                clearInterval(interval);
                progressFill.style.width = '100%';
                progressDetail.textContent = 'Model loaded successfully!';
                setTimeout(() => {
                    progressBox.style.display = 'none';
                }, 2000);
            },
            error: () => {
                clearInterval(interval);
                progressBox.style.display = 'none';
            }
        };
    }

    // Enhanced fetch with dynamic timeout
    async function fetchWithTimeout(url, options = {}, customTimeout = null) {
        const timeout = customTimeout || API_CONFIG.DEFAULT_TIMEOUT;
        const controller = new AbortController();
        const timeoutId = setTimeout(() => controller.abort(), timeout);
        
        try {
            const response = await fetch(url, {
                ...options,
                signal: controller.signal
            });
            clearTimeout(timeoutId);
            return response;
        } catch (error) {
            clearTimeout(timeoutId);
            if (error.name === 'AbortError') {
                throw new Error(`Request timeout after ${timeout / 1000}s. Try increasing the timeout or using a smaller model.`);
            }
            throw error;
        }
    }

    // Enhanced error handling and JSON parsing
    async function safeJson(resp) {
        const contentType = resp.headers.get('content-type');
        if (contentType && contentType.includes('application/json')) {
            try {
                return await resp.json();
            } catch (e) {
                console.error('JSON parse error:', e);
                return { error: 'Invalid JSON response', status: resp.status, statusText: resp.statusText };
            }
        }
        try {
            const text = await resp.text();
            return { error: text || 'Non-JSON response', status: resp.status, statusText: resp.statusText };
        } catch (e) {
            return { error: 'Failed to read response', status: resp.status, statusText: resp.statusText };
        }
    }

    // Enhanced system health check
    async function checkSystemHealth() {
        const healthEl = document.getElementById('health-status');
        const serverStatus = document.getElementById('server-status');
        const modelManagerStatus = document.getElementById('model-manager-status');
        const connectionStatus = document.getElementById('connection-status');
        const connectionMessage = document.getElementById('connection-message');
        
        healthEl.style.display = 'block';
        healthEl.innerHTML = 'Checking system health...';
        connectionStatus.style.display = 'block';
        connectionMessage.textContent = 'Checking connections...';
        
        let serverHealthy = false;
        let modelManagerHealthy = false;
        
        try {
            console.log('Checking TorchWeave server health...');
            const serverResponse = await fetchWithTimeout('/health');
            const serverHealth = await safeJson(serverResponse);
            serverHealthy = serverResponse.ok;
            serverStatus.innerHTML = serverResponse.ok ? '✅ Online (Port 8000)' : `❌ Offline (${serverResponse.status})`;
            
            if (!serverResponse.ok) {
                console.error('TorchWeave server error:', serverHealth);
            }
        } catch (err) {
            console.error('TorchWeave server connection error:', err);
            serverStatus.innerHTML = `❌ Connection Error: ${err.message}`;
        }
        
        try {
            console.log('Checking Model Manager health...');
            const modelResponse = await fetchWithTimeout('/models/available');
            const modelHealth = await safeJson(modelResponse);
            modelManagerHealthy = modelResponse.ok;
            modelManagerStatus.innerHTML = modelResponse.ok ? '✅ Online (Port 8001)' : `❌ Offline (${modelResponse.status})`;
            
            if (!modelResponse.ok) {
                console.error('Model Manager error:', modelHealth);
            }
        } catch (err) {
            console.error('Model Manager connection error:', err);
            modelManagerStatus.innerHTML = `❌ Connection Error: ${err.message}`;
        }
        
        systemHealthy = serverHealthy && modelManagerHealthy;
        
        if (systemHealthy) {
            connectionStatus.className = 'connection-status connected';
            connectionMessage.textContent = 'All services are online and ready';
            healthEl.innerHTML = `
                <strong>✅ System Health: Excellent</strong><br>
                TorchWeave Server: Online<br>
                Model Manager: Online<br>
                Status: Ready for inference
            `;
        } else {
            connectionStatus.className = 'connection-status';
            connectionMessage.innerHTML = `
                <strong>Connection Issues Detected:</strong><br>
                ${!serverHealthy ? '• TorchWeave Server (Port 8000) - Not responding<br>' : ''}
                ${!modelManagerHealthy ? '• Model Manager (Port 8001) - Not responding<br>' : ''}
                <strong>Troubleshooting:</strong><br>
                1. Ensure Docker containers are running: <code>docker-compose ps</code><br>
                2. Check container logs: <code>docker-compose logs</code><br>
                3. Restart services: <code>docker-compose restart</code>
            `;
            healthEl.innerHTML = `
                <strong>⚠️ System Health: Issues Detected</strong><br>
                Please check the connection status above and ensure all services are running.
            `;
        }
    }

    // Enhanced model loading with better progress tracking and error handling
    document.getElementById('load-model-form').addEventListener('submit', async (e) => {
        e.preventDefault();
        
        if (!systemHealthy) {
            showError('load-error', 'System health check required. Please check system health first.');
            return;
        }
        
        const formData = new FormData(e.target);
        const modelId = formData.get('custom_model_id') || formData.get('model_id');
        const loadBothServices = document.getElementById('load-both-services').checked;
        
        if (!modelId) {
            showError('load-error', 'Please select or enter a model ID');
            return;
        }

        const btn = e.target.querySelector('button[type="submit"]');
        const originalText = btn.textContent;
        btn.innerHTML = '<span class="spinner"></span> Loading Model...';
        btn.disabled = true;

        const progress = showLoadingProgress(modelId);
        hideError('load-error');
        hideResult('load-result');

        try {
            console.log(`Loading model: ${modelId}, Both services: ${loadBothServices}`);
            
            const modelLoadTimeout = API_CONFIG.MODEL_LOAD_TIMEOUT;
            let promises = [];
            let serviceNames = [];

            // Always load in Model Manager (baseline)
            promises.push(
                fetchWithTimeout('/models/load', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ model_id: modelId })
                }, modelLoadTimeout)
            );
            serviceNames.push('Model Manager');

            // Optionally load in TorchWeave server
            if (loadBothServices) {
                promises.push(
                    fetchWithTimeout('/models/load', {
                        method: 'POST',
                        headers: { 'Content-Type': 'application/json' },
                        body: JSON.stringify({ model_id: modelId })
                    }, modelLoadTimeout)
                );
                serviceNames.push('TorchWeave Server');
            }

            const results = await Promise.allSettled(promises);

            let successCount = 0;
            let errors = [];

            for (let i = 0; i < results.length; i++) {
                const result = results[i];
                const serviceName = serviceNames[i];

                if (result.status === 'fulfilled' && result.value.ok) {
                    successCount++;
                    console.log(`Model loaded successfully in ${serviceName}`);
                } else {
                    const error = result.status === 'rejected' 
                        ? result.reason.message
                        : await safeJson(result.value);
                    errors.push(`${serviceName}: ${error.detail || error.error || 'Load failed'}`);
                }
            }

            progress.complete();

            if (successCount >= 1) {
                showResult('load-result', `✅ Model loaded: <code>${modelId}</code><br>
                    Services: ${successCount}/${promises.length} successful<br>
                    ${successCount === promises.length ? '✅ All services ready' : '⚠️ Partial success - check errors below'}
                `);
                
                // Update baseline form with loaded model
                document.getElementById('bl-model').value = modelId;
                
                if (errors.length > 0) {
                    showError('load-error', `Partial success. Issues: ${errors.join('; ')}`);
                }
            } else {
                progress.error();
                showError('load-error', `Failed to load model: ${errors.join('; ')}`);
                hideResult('load-result');
            }

        } catch (err) {
            console.error('Model loading error:', err);
            progress.error();
            showError('load-error', `Network error: ${err.message}`);
            hideResult('load-result');
        } finally {
            btn.textContent = originalText;
            btn.disabled = false;
        }
    });

    // Enhanced TorchWeave generation with proper timeout handling
    document.getElementById('torchweave-form').addEventListener('submit', async (e) => {
        e.preventDefault();
        
        const formData = new FormData(e.target);
        const payload = {
            prompt: formData.get('prompt'),
            max_new_tokens: parseInt(formData.get('max_new_tokens')) || 128,
            temperature: parseFloat(formData.get('temperature')) || 0.7
        };

        if (!payload.prompt?.trim()) {
            showError('tw-error', 'Please enter a prompt');
            return;
        }

        const btn = e.target.querySelector('button[type="submit"]');
        const originalText = btn.textContent;
        btn.innerHTML = '<span class="spinner"></span> Generating...';
        btn.disabled = true;

        try {
            console.log('TorchWeave generation request:', payload);
            const response = await fetchWithTimeout('/v1/generate', {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify(payload)
            }, API_CONFIG.GENERATION_TIMEOUT);
            
            const result = await safeJson(response);
            console.log('TorchWeave response:', result);
            
            if (response.ok && result.generated_text !== undefined) {
                lastTorchweaveResult = result;
                const m = result.metrics || {};
                showResult('tw-result',
                    `<strong>Generated Text:</strong><br>${escapeHtml(result.generated_text || 'No text generated')}<br><br>` +
                    `<strong>Performance Metrics:</strong><br>` +
                    `• Total Time: ${fmtNum(m.total_time)}s<br>` +
                    `• TTFT Estimate: ${fmtNum(m.ttft_estimate)}s<br>` +
                    `• Tokens/sec: ${fmtNum(m.tokens_per_second, 1)}<br>` +
                    `• Method: ${m.method || 'N/A'}`);
                hideError('tw-error');
            } else {
                const errorMsg = result.detail || result.error || `HTTP ${response.status}: ${response.statusText}`;
                showError('tw-error', errorMsg);
                hideResult('tw-result');
            }
        } catch (err) {
            console.error('TorchWeave generation error:', err);
            showError('tw-error', `Generation error: ${err.message}`);
            hideResult('tw-result');
        } finally {
            btn.textContent = originalText;
            btn.disabled = false;
        }
    });

    // Enhanced baseline generation
    document.getElementById('baseline-form').addEventListener('submit', async (e) => {
        e.preventDefault();
        
        const formData = new FormData(e.target);
        const modelId = formData.get('model_id');
        const prompt = formData.get('prompt');

        if (!modelId?.trim()) {
            showError('bl-error', 'Please enter a model ID');
            return;
        }
        
        if (!prompt?.trim()) {
            showError('bl-error', 'Please enter a prompt');  
            return;
        }

        const btn = e.target.querySelector('button[type="submit"]');
        const originalText = btn.textContent;
        btn.innerHTML = '<span class="spinner"></span> Generating...';
        btn.disabled = true;

        try {
            console.log('Baseline generation request with model:', modelId);
            const response = await fetchWithTimeout('/models/generate', {
                method: 'POST',
                body: formData
            }, API_CONFIG.GENERATION_TIMEOUT);
            
            const result = await safeJson(response);
            console.log('Baseline response:', result);
            
            if (response.ok && result.generated_text !== undefined) {
                lastBaselineResult = result;
                const m = result.metrics || {};
                showResult('bl-result',
                    `<strong>Generated Text:</strong><br>${escapeHtml(result.generated_text || 'No text generated')}<br><br>` +
                    `<strong>Performance Metrics:</strong><br>` +
                    `• Total Time: ${fmtNum(m.total_time)}s<br>` +
                    `• Generation Time: ${fmtNum(m.generation_time)}s<br>` +
                    `• TTFT Estimate: ${fmtNum(m.ttft_estimate)}s<br>` +
                    `• Tokens/sec: ${fmtNum(m.tokens_per_second, 1)}<br>` +
                    `• Token Count: ${m.token_count ?? 'N/A'}<br>` +
                    `• Method: ${m.method || 'N/A'}`);
                hideError('bl-error');
            } else {
                const errorMsg = result.detail || result.error || `HTTP ${response.status}: ${response.statusText}`;
                showError('bl-error', errorMsg);
                hideResult('bl-result');
            }
        } catch (err) {
            console.error('Baseline generation error:', err);
            showError('bl-error', `Generation error: ${err.message}`);
            hideResult('bl-result');
        } finally {
            btn.textContent = originalText;
            btn.disabled = false;
        }
    });

    // Enhanced comparison function
    async function runComparison() {
        if (!systemHealthy) {
            alert('Please check system health first. Some services appear to be offline.');
            return;
        }

        const prompt = document.getElementById('tw-prompt').value;
        if (!prompt?.trim()) {
            alert('Please enter a prompt for comparison');
            return;
        }
        
        // Sync prompts
        document.getElementById('bl-prompt').value = prompt;

        const twPayload = {
            prompt,
            max_new_tokens: parseInt(document.getElementById('tw-tokens').value) || 128,
            temperature: parseFloat(document.getElementById('tw-temp').value) || 0.7
        };

        const blForm = new FormData();
        blForm.set('model_id', document.getElementById('bl-model').value || 'distilgpt2');
        blForm.set('prompt', prompt);
        blForm.set('max_length', document.getElementById('bl-length').value || '128');
        blForm.set('temperature', document.getElementById('bl-temp').value || '0.7');

        console.log('Running side-by-side comparison...');

        try {
            const generationTimeout = API_CONFIG.GENERATION_TIMEOUT;
            
            const [twResp, blResp] = await Promise.allSettled([
                fetchWithTimeout('/v1/generate', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify(twPayload)
                }, generationTimeout),
                fetchWithTimeout('/models/generate', {
                    method: 'POST',
                    body: blForm
                }, generationTimeout)
            ]);

            // Handle TorchWeave response
            if (twResp.status === 'fulfilled' && twResp.value.ok) {
                const twJson = await safeJson(twResp.value);
                lastTorchweaveResult = twJson;
                const m = twJson.metrics || {};
                showResult('tw-result',
                    `<strong>Generated Text:</strong><br>${escapeHtml(twJson.generated_text || '')}<br><br>` +
                    `<strong>Performance Metrics:</strong><br>` +
                    `• Total Time: ${fmtNum(m.total_time)}s<br>` +
                    `• TTFT Estimate: ${fmtNum(m.ttft_estimate)}s<br>` +
                    `• Tokens/sec: ${fmtNum(m.tokens_per_second, 1)}<br>` +
                    `• Method: ${m.method || 'N/A'}`);
                hideError('tw-error');
            } else {
                const error = twResp.status === 'rejected' 
                    ? twResp.reason.message
                    : (await safeJson(twResp.value)).error || 'TorchWeave generation failed';
                showError('tw-error', error);
                hideResult('tw-result');
            }

            // Handle Baseline response
            if (blResp.status === 'fulfilled' && blResp.value.ok) {
                const blJson = await safeJson(blResp.value);
                lastBaselineResult = blJson;
                const m = blJson.metrics || {};
                showResult('bl-result',
                    `<strong>Generated Text:</strong><br>${escapeHtml(blJson.generated_text || '')}<br><br>` +
                    `<strong>Performance Metrics:</strong><br>` +
                    `• Total Time: ${fmtNum(m.total_time)}s<br>` +
                    `• Generation Time: ${fmtNum(m.generation_time)}s<br>` +
                    `• TTFT Estimate: ${fmtNum(m.ttft_estimate)}s<br>` +
                    `• Tokens/sec: ${fmtNum(m.tokens_per_second, 1)}<br>` +
                    `• Token Count: ${m.token_count ?? 'N/A'}<br>` +
                    `• Method: ${m.method || 'N/A'}`);
                hideError('bl-error');
            } else {
                const error = blResp.status === 'rejected'
                    ? blResp.reason.message
                    : (await safeJson(blResp.value)).error || 'Baseline generation failed';
                showError('bl-error', error);
                hideResult('bl-result');
            }

            // Show comparison if both succeeded
            if (lastTorchweaveResult && lastBaselineResult) {
                showMetricsComparison();
            }

        } catch (err) {
            console.error('Comparison error:', err);
            showError('tw-error', `Comparison error: ${err.message}`);
            showError('bl-error', `Comparison error: ${err.message}`);
        }
    }

    // Enhanced metrics comparison
    function showMetricsComparison() {
        if (!lastTorchweaveResult || !lastBaselineResult) {
            alert('Please run both TorchWeave and Baseline generation first');
            return;
        }
        
        const comparisonEl = document.getElementById('metrics-comparison');
        const tableBody = document.getElementById('metrics-table-body');
        const summaryEl = document.getElementById('performance-summary');
        
        const tw = lastTorchweaveResult.metrics || {};
        const bl = lastBaselineResult.metrics || {};
        const toS = (v, d=3) => (typeof v === 'number' ? v.toFixed(d) : 'N/A');

        const comps = [
            {
                metric: 'Total Time',
                tw: toS(tw.total_time) + 's',
                bl: toS(bl.total_time) + 's',
                winner: (numOr(tw.total_time, 1e9)) < (numOr(bl.total_time, 1e9)) ? 'TorchWeave' : 'Baseline'
            },
            {
                metric: 'TTFT (Time to First Token)',
                tw: toS(tw.ttft_estimate) + 's',
                bl: toS(bl.ttft_estimate) + 's',
                winner: (numOr(tw.ttft_estimate, 1e9)) < (numOr(bl.ttft_estimate, 1e9)) ? 'TorchWeave' : 'Baseline'
            },
            {
                metric: 'Tokens per Second',
                tw: toS(tw.tokens_per_second, 1),
                bl: toS(bl.tokens_per_second, 1),
                winner: (numOr(tw.tokens_per_second, 0)) > (numOr(bl.tokens_per_second, 0)) ? 'TorchWeave' : 'Baseline'
            },
            {
                metric: 'Token Count',
                tw: tw.estimated_token_count ?? tw.token_count ?? 'N/A',
                bl: bl.token_count ?? 'N/A',
                winner: 'Similar'
            }
        ];
        
        tableBody.innerHTML = comps.map(c => `
            <tr>
                <td><strong>${c.metric}</strong></td>
                <td class="${c.winner === 'TorchWeave' ? 'performance-winner' : ''}">${c.tw}</td>
                <td class="${c.winner === 'Baseline' ? 'performance-winner' : ''}">${c.bl}</td>
                <td><strong>${c.winner}</strong></td>
            </tr>
        `).join('');
        
        const twWins = comps.filter(c => c.winner === 'TorchWeave').length;
        const blWins = comps.filter(c => c.winner === 'Baseline').length;
        
        summaryEl.innerHTML = `
            <strong>Performance Summary:</strong><br>
            TorchWeave wins: ${twWins} metrics<br>
            Baseline wins: ${blWins} metrics<br>
            <strong>Overall Winner: ${twWins > blWins ? 'TorchWeave' : (blWins > twWins ? 'Baseline' : 'Tie')}</strong>
        `;
        
        comparisonEl.style.display = 'block';
    }

    // Model management functions with better error handling
    async function viewModels(){
        const box = document.getElementById('model-info');
        const content = document.getElementById('model-info-content');
        try{
            const r = await fetchWithTimeout('/models/loaded');
            const d = await safeJson(r);
            if (r.ok) {
                content.innerHTML = `<strong>Loaded Models:</strong><pre>${escapeHtml(JSON.stringify(d,null,2))}</pre>`;
            } else {
                content.innerHTML = `<strong>Error loading models:</strong> ${d.error || d.detail || 'Unknown error'}`;
            }
        }catch(e){
            console.error('Error viewing models:', e);
            content.innerHTML = `<strong>Connection Error:</strong> ${escapeHtml(e.message)}`;
        }finally{ 
            box.style.display='block'; 
        }
    }

    async function viewAvailable(){
        const box = document.getElementById('model-info');
        const content = document.getElementById('model-info-content');
        try{
            const r = await fetchWithTimeout('/models/available');
            const d = await safeJson(r);
            if (r.ok) {
                content.innerHTML = `<strong>Available Models:</strong><pre>${escapeHtml(JSON.stringify(d,null,2))}</pre>`;
            } else {
                content.innerHTML = `<strong>Error loading available models:</strong> ${d.error || d.detail || 'Unknown error'}`;
            }
        }catch(e){
            console.error('Error viewing available models:', e);
            content.innerHTML = `<strong>Connection Error:</strong> ${escapeHtml(e.message)}`;
        }finally{ 
            box.style.display='block'; 
        }
    }

    async function viewStats(){
        const infoBox = document.getElementById('model-info');
        const infoContent = document.getElementById('model-info-content');
        try{
            const [serverHealthResp, modelStatsResp] = await Promise.allSettled([
                fetchWithTimeout('/health'),
                fetchWithTimeout('/system/stats')
            ]);

            let healthData = {};
            let statsData = {};
            
            if (serverHealthResp.status === 'fulfilled') {
                healthData = await safeJson(serverHealthResp.value);
            }
            
            if (modelStatsResp.status === 'fulfilled') {
                statsData = await safeJson(modelStatsResp.value);
            }

            const serverOk = serverHealthResp.status === 'fulfilled' && serverHealthResp.value.ok ? '✅' : '❌';
            const modelOk = modelStatsResp.status === 'fulfilled' && modelStatsResp.value.ok ? '✅' : '❌';

            infoContent.innerHTML = `
                <strong>System Stats:</strong><br>
                <em>TorchWeave Server:</em> ${serverOk} ${serverHealthResp.status === 'fulfilled' ? 'Connected' : 'Failed'}<br>
                <em>Model Manager:</em> ${modelOk} ${modelStatsResp.status === 'fulfilled' ? 'Connected' : 'Failed'}<br><br>
                <details>
                    <summary>Raw Data (Click to expand)</summary>
                    <pre>${escapeHtml(JSON.stringify({
                        server_health: healthData,
                        model_manager_stats: statsData
                    }, null, 2))}</pre>
                </details>
            `;
        }catch(e){
            console.error('Error viewing stats:', e);
            infoContent.innerHTML = `<strong>Error:</strong> ${escapeHtml(e.message)}`;
        }finally{
            infoBox.style.display='block';
        }
    }

    // Utility functions
    function showResult(id, message){ 
        const el = document.getElementById(id); 
        el.innerHTML = message; 
        el.style.display = 'block'; 
    }
    
    function hideResult(id){ 
        document.getElementById(id).style.display = 'none'; 
    }
    
    function showError(id, message){ 
        const el = document.getElementById(id); 
        el.innerHTML = `<strong>Error:</strong> ${escapeHtml(message)}`; 
        el.style.display = 'block'; 
    }
    
    function hideError(id){ 
        document.getElementById(id).style.display = 'none'; 
    }

    function fmtNum(v, dec=3){ 
        return (typeof v === 'number' && isFinite(v)) ? v.toFixed(dec) : 'N/A'; 
    }
    
    function numOr(v, fallback){ 
        return (typeof v === 'number' && isFinite(v)) ? v : fallback; 
    }
    
    function escapeHtml(s){
        return String(s).replace(/[&<>"'`=\/]/g, c => ({
            '&':'&amp;','<':'&lt;','>':'&gt;','"':'&quot;',"'":'&#39;','/':'&#x2F;','`':'&#x60;','=':'&#x3D;'
        }[c]));
    }

    // Initialize the page
    document.addEventListener('DOMContentLoaded', function() {
        console.log('TorchWeave frontend initialized with enhanced timeout handling');
        // Run initial health check
        setTimeout(checkSystemHealth, 1000);
        // Update model warning on page load
        updateModelWarning();
    });
</script>
</body>
</html>
